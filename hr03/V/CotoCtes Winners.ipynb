{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58115, 4) (5000, 4)\n",
      "Náklaďáku praskla pneumatika, převrátil se a zasypal silnici pískem => zpr\n",
      "Nástupkyně Natalie. Novinářka Suková zkusí navázat na tenisovou dynastii => spo\n",
      "   cat                            other  \\\n",
      "0  zpr  A170809_114631_praha-zpravy_rsr   \n",
      "1  spo         A170813_203426_tenis_rou   \n",
      "2  spo  A170807_070846_sport-basket_ten   \n",
      "4  zpr        A151226_141456_domaci_pku   \n",
      "5  zpr   A170303_143744_plzen-zpravy_pp   \n",
      "\n",
      "                                                data  yr  \n",
      "0  Náklaďáku praskla pneumatika, převrátil se a z...  17  \n",
      "1  Nástupkyně Natalie. Novinářka Suková zkusí nav...  17  \n",
      "2  Rozdílné cesty na ME: juniorky s rekordem, jun...  17  \n",
      "4  Svět je složitější, než jak nám líčí z Lán, re...  15  \n",
      "5  Prodala šéfka kočičího spolku vilu pod cenou? ...  17  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#filename = r'C:\\P\\Machine Learning\\cotoctes\\ucici.csv'\n",
    "filename = r'C:\\P\\Machine Learning\\cotoctes\\ucici_full.csv'\n",
    "import pandas as pd\n",
    "#training = pd.read_csv(filename,delimiter='|',header=None,names = ['cat', 'data'])\n",
    "training = pd.read_csv(filename,delimiter='|',header=None,names = ['cat','other', 'data'])\n",
    "training['yr'] = training['other'].str.slice(1, 3)\n",
    "training = training[training['yr'].isin(['15','16','17'])]\n",
    "X_train,X_test = training[0:-5000],training[-5000:]\n",
    "\n",
    "print(X_train.shape,X_test.shape)\n",
    "for a, b in zip(X_train.data[0:2], X_train.cat[0:2]):\n",
    "    print(\"{0} => {1}\".format(a,b))\n",
    "    \n",
    "#def size_mb(docs):\n",
    "#    return sum(len(s.encode('utf-8')) for s in docs) / 1e6\n",
    "\n",
    "#data_train_size_mb = size_mb(X_train.data)\n",
    "#data_test_size_mb = size_mb(X_test.data)\n",
    "\n",
    "#print(\"%d items - %0.3fMB (training set)\" % (\n",
    "#    len(X_train.data), data_train_size_mb))\n",
    "#print(\"%d items - %0.3fMB (test set)\" % (\n",
    "#    len(X_test.data), data_test_size_mb))\n",
    "print(X_train.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'solver': [('adam')],\n",
    "    'alpha': (0.001, 0.00001, 0.000001),\n",
    "    'hidden_layer_sizes': [(4)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.001, 'hidden_layer_sizes': 4, 'solver': 'adam'}\n",
      "Testing 1.00 / Training 0.95\n",
      "done in 14805.662s\n",
      "{'alpha': 1e-05, 'hidden_layer_sizes': 4, 'solver': 'adam'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v.dekanovsky\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 0.59 / Training 0.59\n",
      "done in 174.213s\n",
      "{'alpha': 1e-06, 'hidden_layer_sizes': 4, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "for p in list(ParameterGrid(parameters)):\n",
    "    t0 = time()\n",
    "    print(p)\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', HashingVectorizer()),\n",
    "        ('clf', MLPClassifier(**p)),\n",
    "        ])\n",
    "    pipeline.fit(X_train.data, X_train.cat)\n",
    "    print(\"Testing {0:.2f} / Training {1:.2f}\".format(np.mean(pipeline.predict(X_train.data) == X_train.cat),np.mean(pipeline.predict(X_test.data) == X_test.cat)))\n",
    "    print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = r'C:\\P\\Machine Learning\\cotoctes\\testovaci.csv'\n",
    "testing = pd.read_csv(filename,delimiter='|',header=None,names = ['data'])\n",
    "#with open(r'C:\\P\\Machine Learning\\cotoctes\\outputBestMPL.csv','w') as f:\n",
    "#    wr = csv.writer(f, delimiter='\\n')\n",
    "#    wr.writerow(gs_clf.predict(testing.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 1.00 / Training 0.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.linear_model import Perceptron\n",
    "#from sknn.mlp import MultiLayerPerceptron\n",
    "pipeline2 = Pipeline([\n",
    "        ('vect',Pipeline([\n",
    "                   ('union', FeatureUnion(\n",
    "                           transformer_list=[\n",
    "                       ('words', CountVectorizer(analyzer='word',ngram_range=(1,2))),\n",
    "                       ('chars', CountVectorizer(analyzer='char',ngram_range=(1,3))),\n",
    "                        ],)),\n",
    "                   ('tfidf', TfidfTransformer(use_idf=False)),   \n",
    "                    ])),\n",
    "        ('clf', Perceptron(max_iter=25)),\n",
    "        #('clf', MultiLayerPerceptron(max_iter=50,dropout_rate=0.5)),\n",
    "        ])\n",
    "pipeline2.fit(X_train.data, X_train.cat)\n",
    "print(\"Testing {0:.2f} / Training {1:.2f}\".format(np.mean(pipeline2.predict(X_train.data) == X_train.cat),np.mean(pipeline2.predict(X_test.data) == X_test.cat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(r'C:\\P\\Machine Learning\\cotoctes\\outputCountPercFull.csv','w') as f:\n",
    "    wr = csv.writer(f, delimiter='\\n')\n",
    "    wr.writerow(pipeline2.predict(testing.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tec'], \n",
       "      dtype='<U3')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2.predict(['Pioneer má první interní mechaniku pro přehrávání Ultra HD disků na PC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                data  cat\n",
      "0  Celtic znemožnil v boji o Ligu mistrů Astanu, ...  spo\n",
      "1  Katar obnovuje plné diplomatické styky s Íráne...  zpr\n",
      "2  Před 100 lety se narodil česko-židovský badate...  tec\n",
      "3  Pioneer má první interní mechaniku pro přehráv...  tec\n",
      "4  Studie z Černobylu tvrdí, že radiace zvířatům ...  spo\n",
      "5   Černý pátek je tu. Jak a kde si počíhat na slevy  tec\n",
      "6  Karolína Plíšková začne hájit trůn. O číslo 1 ...  spo\n",
      "7  Od Facebooku nemůžete čekat žádné soukromí, od...  tec\n",
      "8  Oparům se lze bránit. Pomohou antivirotika i p...  ona\n",
      "9  Vyhovuje nám, že nás předem odepisují, soudí z...  spo\n",
      "                                                  data  cat\n",
      "990  Jsme stříbrní, utěšují se američtí fotbalisté ...  spo\n",
      "991  Závislost na plastikách mi zničila sexuální ži...  ona\n",
      "992  Internet, jak jej známe, může skončit, varoval...  tec\n",
      "993  V případě řízení s firmou FAU mohla být poruše...  zpr\n",
      "994  Pokrok v IT je obrovský, ale skrytý, řekl šéf ...  spo\n",
      "995  Cítím se jako junior, těší Federera. A vyhlíží...  spo\n",
      "996  Google ukončí vývoj oblíbeného editoru Picasa,...  tec\n",
      "997  Spotify hlásí 100 milionů uživatelů měsíčně. A...  tec\n",
      "998  Software zdarma: Windows vždy ve skvělém stavu...  tec\n",
      "999  Vyzkoušela jsem mraky diet, říká zpěvačka Ilon...  ona\n"
     ]
    }
   ],
   "source": [
    "testing['cat'] = pipeline2.predict(testing.data)\n",
    "print(testing.head(10))\n",
    "print(testing.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
