{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is not a text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 data\n",
       "0      This is a text\n",
       "1  This is not a text"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "texts = ['This is a text','This is not a text']\n",
    "textFrame = pd.DataFrame(texts, columns=['data'])\n",
    "textFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 unique tokens.\n",
      "Shape of data tensor: (2, 6)\n",
      "[[0 0 1 2 3 4]\n",
      " [0 1 2 5 3 4]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a text</td>\n",
       "      <td>[0, 0, 1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is not a text</td>\n",
       "      <td>[0, 1, 2, 5, 3, 4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 data            sequence\n",
       "0      This is a text  [0, 0, 1, 2, 3, 4]\n",
       "1  This is not a text  [0, 1, 2, 5, 3, 4]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences \n",
    "from keras.utils import to_categorical\n",
    "\n",
    "max_review_length = 6 #maximum length of the sentence\n",
    "embedding_vecor_length = 3\n",
    "top_words = 10\n",
    "\n",
    "#num_words is tne number of unique words in the sequence, if there's more top count words are taken\n",
    "tokenizer = Tokenizer(top_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "input_dim = len(word_index) + 1\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "#max_review_length is the maximum length of the input text so that we can create vector [... 0,0,1,3,50] where 1,3,50 are individual words\n",
    "data = pad_sequences(sequences, max_review_length)\n",
    "\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print(data)\n",
    "textFrame['sequence'] = data.tolist()\n",
    "textFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>sequence</th>\n",
       "      <th>Embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a text</td>\n",
       "      <td>[0, 0, 1, 2, 3, 4]</td>\n",
       "      <td>[-0.0014113187789916992, 0.008530724793672562,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is not a text</td>\n",
       "      <td>[0, 1, 2, 5, 3, 4]</td>\n",
       "      <td>[-0.0014113187789916992, 0.008530724793672562,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 data            sequence  \\\n",
       "0      This is a text  [0, 0, 1, 2, 3, 4]   \n",
       "1  This is not a text  [0, 1, 2, 5, 3, 4]   \n",
       "\n",
       "                                           Embedding  \n",
       "0  [-0.0014113187789916992, 0.008530724793672562,...  \n",
       "1  [-0.0014113187789916992, 0.008530724793672562,...  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words , embedding_vecor_length, input_length=max_review_length))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "output_array = model.predict(data)\n",
    "output_array\n",
    "\n",
    "textFrame['Embedding'] = output_array.tolist()\n",
    "pd.set_option('precision',2)\n",
    "textFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_34 (Embedding)     (None, 6, 3)              30        \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 18)                0         \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class_name': 'Embedding',\n",
       "  'config': {'activity_regularizer': None,\n",
       "   'batch_input_shape': (None, 6),\n",
       "   'dtype': 'float32',\n",
       "   'embeddings_constraint': None,\n",
       "   'embeddings_initializer': {'class_name': 'RandomUniform',\n",
       "    'config': {'maxval': 0.05, 'minval': -0.05, 'seed': None}},\n",
       "   'embeddings_regularizer': None,\n",
       "   'input_dim': 10,\n",
       "   'input_length': 6,\n",
       "   'mask_zero': False,\n",
       "   'name': 'embedding_34',\n",
       "   'output_dim': 3,\n",
       "   'trainable': True}},\n",
       " {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True}}]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'embedding_34', 'trainable': True, 'batch_input_shape': (None, 6), 'dtype': 'float32', 'input_dim': 10, 'output_dim': 3, 'embeddings_initializer': {'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False, 'input_length': 6}\n",
      "[array([[-0.00141132,  0.00853072,  0.02273766],\n",
      "       [ 0.03596164, -0.03251224, -0.04678869],\n",
      "       [-0.02188659,  0.00193819, -0.00553908],\n",
      "       [-0.00947953, -0.04847676,  0.00643707],\n",
      "       [-0.01232052,  0.03661312,  0.03740862],\n",
      "       [-0.04615786, -0.0401098 , -0.02656391],\n",
      "       [ 0.00160072,  0.02230993, -0.02462446],\n",
      "       [-0.01392549,  0.00434928,  0.03618317],\n",
      "       [ 0.0289198 ,  0.01454613, -0.01566162],\n",
      "       [-0.01825454, -0.0113125 ,  0.04260141]], dtype=float32)]\n",
      "{'name': 'flatten_3', 'trainable': True}\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.get_config())\n",
    "    print(layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.00141132,  0.00853072,  0.02273766],\n",
       "        [ 0.03596164, -0.03251224, -0.04678869],\n",
       "        [-0.02188659,  0.00193819, -0.00553908],\n",
       "        [-0.00947953, -0.04847676,  0.00643707],\n",
       "        [-0.01232052,  0.03661312,  0.03740862],\n",
       "        [-0.04615786, -0.0401098 , -0.02656391],\n",
       "        [ 0.00160072,  0.02230993, -0.02462446],\n",
       "        [-0.01392549,  0.00434928,  0.03618317],\n",
       "        [ 0.0289198 ,  0.01454613, -0.01566162],\n",
       "        [-0.01825454, -0.0113125 ,  0.04260141]], dtype=float32)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00141132,  0.00853072,  0.02273766, -0.00141132,  0.00853072,\n",
       "        0.02273766,  0.03596164, -0.03251224, -0.04678869, -0.02188659,\n",
       "        0.00193819, -0.00553908, -0.00947953, -0.04847676,  0.00643707,\n",
       "       -0.01232052,  0.03661312,  0.03740862], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>sequence</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>EmbeddingsFlatten</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a text</td>\n",
       "      <td>[0, 0, 1, 2, 3, 4]</td>\n",
       "      <td>[-0.0014113187789916992, 0.008530724793672562,...</td>\n",
       "      <td>[-0.04179590940475464, 0.01228167861700058, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is not a text</td>\n",
       "      <td>[0, 1, 2, 5, 3, 4]</td>\n",
       "      <td>[-0.0014113187789916992, 0.008530724793672562,...</td>\n",
       "      <td>[-0.04179590940475464, 0.01228167861700058, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 data            sequence  \\\n",
       "0      This is a text  [0, 0, 1, 2, 3, 4]   \n",
       "1  This is not a text  [0, 1, 2, 5, 3, 4]   \n",
       "\n",
       "                                           Embedding  \\\n",
       "0  [-0.0014113187789916992, 0.008530724793672562,...   \n",
       "1  [-0.0014113187789916992, 0.008530724793672562,...   \n",
       "\n",
       "                                   EmbeddingsFlatten  \n",
       "0  [-0.04179590940475464, 0.01228167861700058, -0...  \n",
       "1  [-0.04179590940475464, 0.01228167861700058, -0...  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words , embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Flatten())\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "output_array = model.predict(data)\n",
    "output_array\n",
    "\n",
    "textFrame['EmbeddingsFlatten'] = output_array.tolist()\n",
    "textFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04179591,  0.01228168, -0.03246965, -0.04179591,  0.01228168,\n",
       "       -0.03246965,  0.01011391, -0.02434975,  0.00832511, -0.03656663,\n",
       "        0.01334569, -0.01831834,  0.00389238,  0.01628676, -0.01201253,\n",
       "        0.01853235,  0.04914785,  0.01473973], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
